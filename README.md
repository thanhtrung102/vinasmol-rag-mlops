# VinaSmol RAG MLOps

Vietnamese LLM (VinaSmol) and RAG System with Production-Grade MLOps Pipeline.

[![CI Pipeline](https://github.com/thanhtrung102/vinasmol-rag-mlops/actions/workflows/ci.yaml/badge.svg)](https://github.com/thanhtrung102/vinasmol-rag-mlops/actions)
![Project Status](https://img.shields.io/badge/Status-100%25_Complete-brightgreen)
![Phase](https://img.shields.io/badge/Phase-7_of_7-brightgreen)
![Production Ready](https://img.shields.io/badge/Production-Ready-success)

## Overview

This project implements a **production-ready MLOps pipeline** for Vietnamese language models and RAG systems:

- **VinaSmol**: Fine-tuning Vietnamese language models using LoRA (PhoGPT-4B-Chat)
- **OpenRAG**: Retrieval-Augmented Generation with hallucination detection and evaluation
- **MLOps**: Comprehensive experiment tracking, monitoring, CI/CD, and observability

### ğŸ¯ Project Status: **100% COMPLETE** âœ¨ (7 of 7 Phases)

| Phase | Status | Description |
|-------|--------|-------------|
| 1. Data Pipeline | âœ… Complete | Vietnamese text processing from Common Crawl |
| 2. Training Infrastructure | âœ… Complete | MLflow + LoRA fine-tuning |
| 3. RAG System | âœ… Complete | Qdrant + FastAPI + Reranking |
| 4. Evaluation Framework | âœ… Complete | Ragas + Hallucination detection |
| 5. Monitoring Stack | âœ… Complete | Prometheus + Grafana + LangFuse |
| 6. Infrastructure as Code | âœ… Complete | Terraform modules (GCP) |
| 7. CI/CD Pipeline | âœ… Complete | GitHub Actions with quality gates |

**ğŸ‰ All phases complete! Production-ready MLOps system for Vietnamese LLM and RAG.**

ğŸ“Š [**View Detailed Status**](PROJECT_STATUS_UPDATE.md) | ğŸ“‹ [**Implementation Plan**](IMPLEMENTATION_PLAN.md)

## Quick Start (GitHub Codespaces)

[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/YOUR_USERNAME/vinasmol-rag-mlops)

**Requirements**:
- 4-core, 16GB RAM, 32GB storage Codespace
- **GPU required for training** (use GPU-enabled Codespace or cloud GPU instance)
- Standard Codespaces work for API/RAG features only

```bash
# Setup is automatic via postCreateCommand
# Or manually run:
make setup

# Start all services
make services-up

# Run tests (doesn't require GPU)
make test
```

### For Training (Requires GPU)

Use one of these GPU-enabled environments:
- **GitHub Codespaces**: GPU-enabled instance (select GPU machine type)
- **Google Colab**: Free T4 GPU available
- **Kaggle Notebooks**: Free GPU available
- **Local**: NVIDIA GPU with CUDA 11.8+

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA LAYER                                  â”‚
â”‚  Common Crawl â†’ Vietnamese Filter â†’ Text Processing â†’ Embeddings    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      TRAINING LAYER                                 â”‚
â”‚  MLflow Tracking â”‚ W&B Prompts â”‚ HuggingFace Hub â”‚ LoRA Fine-tuning â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SERVING LAYER                                  â”‚
â”‚  FastAPI Gateway â”‚ Qdrant Vectors â”‚ vLLM/Transformers â”‚ Reranking   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MONITORING LAYER                                 â”‚
â”‚  Prometheus â”‚ Grafana â”‚ LangFuse â”‚ Ragas Evaluation â”‚ Evidently     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
vinasmol-rag-mlops/
â”œâ”€â”€ .devcontainer/          # Codespaces configuration
â”œâ”€â”€ .github/workflows/      # CI/CD pipelines
â”œâ”€â”€ configs/                # Configuration files
â”œâ”€â”€ infrastructure/         # Terraform IaC
â”œâ”€â”€ notebooks/              # Jupyter notebooks
â”œâ”€â”€ scripts/                # Utility scripts
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/               # FastAPI application
â”‚   â”œâ”€â”€ data_pipeline/     # Data processing
â”‚   â”œâ”€â”€ evaluation/        # RAG & LLM evaluation
â”‚   â”œâ”€â”€ monitoring/        # Observability
â”‚   â”œâ”€â”€ rag/               # RAG components
â”‚   â””â”€â”€ training/          # Model training
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/              # Unit tests
â”‚   â””â”€â”€ integration/       # Integration tests
â”œâ”€â”€ docker-compose.yaml     # Local services
â”œâ”€â”€ Makefile               # Development commands
â””â”€â”€ requirements.txt       # Python dependencies
```

## Services

All services run via Docker Compose with persistent volumes and health checks.

| Service | Port | Status | Description |
|---------|------|--------|-------------|
| **FastAPI** | 8000 | âœ… Ready | RAG API with streaming support |
| **Qdrant** | 6333 | âœ… Ready | Vector database (v1.11.3) |
| **MLflow** | 8080 | âœ… Ready | Experiment tracking UI |
| **Redis** | 6379 | âœ… Ready | Query result caching |
| **Prometheus** | 9090 | âœ… Ready | Metrics collection with alerts |
| **Grafana** | 3000 | âœ… Ready | 8-panel RAG dashboard (admin/admin) |
| **Postgres** | 5432 | âœ… Ready | MLflow backend store |
| **LangFuse** | Cloud | ğŸ”§ Optional | LLM request tracing |

**Quick Access**:
```bash
# Health checks
curl http://localhost:8000/health
curl http://localhost:6333/health
curl http://localhost:9090/-/healthy

# Metrics
curl http://localhost:8000/metrics
```

## Usage

### 1. Data Pipeline

```bash
# Process Vietnamese text from Common Crawl
make data-process

# Generate embeddings
make data-embed
```

### 2. Training

```bash
# LoRA fine-tuning (optimized for 16GB RAM)
make train-lora
```

### 3. RAG API

```bash
# Start the API server
make api

# Query the RAG system
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Viá»‡t Nam náº±m á»Ÿ Ä‘Ã¢u?"}'
```

### 4. Evaluation

```bash
# Evaluate RAG system
make eval-rag

# Run hallucination detection
make eval-hallucination
```

### 5. Monitoring & Observability

**Full monitoring stack with Prometheus, Grafana, and LangFuse integration.**

```bash
# Start all services (includes monitoring)
make services-up

# Access monitoring dashboards
# Grafana:    http://localhost:3000 (admin/admin)
# Prometheus: http://localhost:9090
# MLflow:     http://localhost:8080
# Metrics:    http://localhost:8000/metrics
```

**Features**:
- âœ… **8-panel Grafana dashboard** - Request rate, error rate, latency (P50/P95/P99), cache hits, retrieval scores
- âœ… **5 Prometheus alert rules** - Error rate, latency, retrieval quality, cache performance, uptime
- âœ… **LangFuse LLM tracing** - Request/response traces with latency and quality metrics
- âœ… **Real-time metrics** - Auto-refresh every 10 seconds

**Optional: Enable LangFuse tracing**:
```bash
export LANGFUSE_PUBLIC_KEY=pk-lf-your-key
export LANGFUSE_SECRET_KEY=sk-lf-your-secret
# Restart API to enable tracing
```

**Generate test metrics**:
```bash
# Send test queries to populate dashboards
for i in {1..10}; do
  curl -X POST http://localhost:8000/query \
    -H "Content-Type: application/json" \
    -d "{\"question\": \"Test query $i\", \"top_k\": 3}"
  sleep 1
done
```

ğŸ“Š **Documentation**:
- [MONITORING_SETUP.md](MONITORING_SETUP.md) - Quick start guide
- [Grafana Dashboard Guide](configs/grafana/dashboards/) - Panel descriptions
- [Alert Rules](configs/alert.rules.yml) - Prometheus alerting configuration

### 6. Infrastructure Deployment

**Deploy to Google Cloud Platform with Terraform**

```bash
# Navigate to Terraform directory
cd infrastructure/terraform

# Initialize Terraform
terraform init

# Plan deployment (development environment)
terraform plan -var-file=environments/dev.tfvars

# Deploy infrastructure
terraform apply -var-file=environments/dev.tfvars

# Get service endpoints
terraform output
```

**Infrastructure provisioned**:
- âœ… API Server (n2-standard-4, Ubuntu 22.04)
- âœ… Training Server (n1-standard-4 + T4 GPU)
- âœ… Cloud Storage buckets (artifacts, data, MLflow)
- âœ… Cloud SQL PostgreSQL (MLflow backend)
- âœ… Memorystore Redis (caching)
- âœ… VPC with firewall rules
- âœ… Auto-deployment via startup scripts

ğŸ“š **Full Documentation**: [infrastructure/terraform/README.md](infrastructure/terraform/README.md)

**Cost Estimates**:
- Development: ~$260/month
- Production: ~$1,110/month

## Demo Guide

### Local Development Demo

**1. Start All Services**:
```bash
# Start Docker Compose services
make services-up

# Wait for services to be healthy (~30 seconds)
docker-compose ps
```

**2. Add Documents to RAG System**:
```bash
# Add Vietnamese documents
curl -X POST http://localhost:8000/documents \
  -H "Content-Type: application/json" \
  -d '{
    "documents": [
      "Viá»‡t Nam lÃ  má»™t quá»‘c gia á»Ÿ ÄÃ´ng Nam Ã. Thá»§ Ä‘Ã´ lÃ  HÃ  Ná»™i.",
      "Phá»Ÿ lÃ  mÃ³n Äƒn truyá»n thá»‘ng cá»§a Viá»‡t Nam, ráº¥t phá»• biáº¿n.",
      "Vá»‹nh Háº¡ Long lÃ  Di sáº£n ThiÃªn nhiÃªn Tháº¿ giá»›i Ä‘Æ°á»£c UNESCO cÃ´ng nháº­n."
    ]
  }'
```

**3. Query the RAG System**:
```bash
# Ask questions in Vietnamese
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Thá»§ Ä‘Ã´ cá»§a Viá»‡t Nam lÃ  gÃ¬?", "top_k": 3}'

# Check cache performance
curl http://localhost:8000/cache/stats
```

**4. View Monitoring Dashboards**:
```bash
# Open in browser:
open http://localhost:3000  # Grafana (admin/admin)
open http://localhost:9090  # Prometheus
open http://localhost:8080  # MLflow

# Generate test traffic to populate dashboards
for i in {1..20}; do
  curl -X POST http://localhost:8000/query \
    -H "Content-Type: application/json" \
    -d "{\"question\": \"Test query $i about Vietnam\", \"top_k\": 3}"
  sleep 2
done
```

**5. Run Evaluation**:
```bash
# Evaluate RAG system quality
make eval-rag

# Run hallucination detection
python -m src.evaluation.vietnamese_benchmark --stats

# View results in MLflow UI
open http://localhost:8080
```

**6. Train Model (Requires GPU)**:
```bash
# Fine-tune PhoGPT with LoRA (requires GPU)
make train-lora

# View training progress in MLflow
open http://localhost:8080
```

### Production Deployment Demo

**1. Deploy Infrastructure**:
```bash
cd infrastructure/terraform

# Deploy to GCP production environment
terraform apply -var-file=environments/prod.tfvars

# Get API server IP
export API_IP=$(terraform output -raw api_server_ip)
```

**2. Access Production Services**:
```bash
# RAG API
curl http://$API_IP:8000/health

# Grafana Dashboard
open http://$API_IP:3000

# MLflow UI
open http://$API_IP:8080

# Prometheus
open http://$API_IP:9090
```

**3. SSH to Servers**:
```bash
# SSH to API server
gcloud compute ssh vinasmol-prod-vm-api --zone=us-central1-a

# SSH to training server (with GPU)
gcloud compute ssh vinasmol-prod-vm-training --zone=us-central1-a
```

**4. Monitor Production Metrics**:
```bash
# View real-time metrics
curl http://$API_IP:8000/metrics

# Check Prometheus alerts
curl http://$API_IP:9090/api/v1/alerts

# View Grafana dashboard
# Navigate to "RAG System Metrics" in Grafana UI
```

**5. Run Production Training**:
```bash
# SSH to training server
gcloud compute ssh vinasmol-prod-vm-training --zone=us-central1-a

# Inside training server
cd vinasmol-rag-mlops
python -m src.training.train_lora \
  --config configs/training_config.yaml \
  --push-to-hub
```

### Feature Showcase

**1. RAG with Caching**:
```bash
# First query (cache miss)
time curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "What is pho?"}'

# Same query (cache hit - much faster)
time curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "What is pho?"}'
```

**2. Streaming Responses**:
```bash
# Stream RAG response
curl -N -X POST http://localhost:8000/query/stream \
  -H "Content-Type: application/json" \
  -d '{"question": "Tell me about Vietnam"}'
```

**3. Document Reranking**:
```bash
# Add more documents
curl -X POST http://localhost:8000/documents \
  -H "Content-Type: application/json" \
  -d '{
    "documents": [
      "Ho Chi Minh City is the largest city in Vietnam.",
      "Vietnamese coffee is famous worldwide.",
      "The Mekong Delta is known for its floating markets."
    ]
  }'

# Query with reranking (top_k triggers reranking)
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Tell me about Vietnamese cities", "top_k": 5}'
```

**4. Prometheus Alerts**:
```bash
# Trigger high error rate alert (send many bad requests)
for i in {1..100}; do
  curl -X POST http://localhost:8000/query \
    -H "Content-Type: application/json" \
    -d '{"question": ""}' &
done

# Check if alert fired
curl http://localhost:9090/api/v1/alerts | jq '.data.alerts[] | select(.labels.alertname=="HighErrorRate")'
```

**5. LangFuse Tracing** (Optional):
```bash
# Set LangFuse credentials
export LANGFUSE_PUBLIC_KEY=pk-lf-your-key
export LANGFUSE_SECRET_KEY=sk-lf-your-secret

# Restart API
docker-compose restart fastapi

# Send queries - traces appear in LangFuse dashboard
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "What is the capital of Vietnam?"}'

# View traces at https://cloud.langfuse.com
```

## Development

```bash
# Install dev dependencies
make install-dev

# Run linting
make lint

# Run formatter
make format

# Run all tests
make test-all

# Pre-commit hooks
make pre-commit
```

## Configuration

Copy `.env.example` to `.env` and configure:

```bash
cp .env.example .env
```

Key settings:
- `MLFLOW_TRACKING_URI`: MLflow server URL
- `QDRANT_HOST`: Vector database host
- `OPENAI_API_KEY`: Required for Ragas evaluation

## Tech Stack

### Core ML/NLP
| Component | Technology | Version |
|-----------|-----------|---------|
| **Base Model** | PhoGPT-4B-Chat (VinAI) | - |
| **Framework** | PyTorch, Transformers | 2.1.0, 4.35.2 |
| **Fine-tuning** | PEFT (LoRA), bitsandbytes | 0.6.2 |
| **Embeddings** | Sentence-Transformers | paraphrase-multilingual-MiniLM-L12-v2 |
| **Text Processing** | FastText, underthesea | Vietnamese language detection |

### RAG System
| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Vector DB** | Qdrant | v1.11.3 - Semantic search |
| **Caching** | Redis | v7-alpine - Query result caching |
| **Reranking** | Cross-encoder | BGE reranker - Result reordering |
| **API** | FastAPI, Uvicorn | Async REST API with streaming |

### MLOps & Monitoring
| Category | Technologies |
|----------|-------------|
| **Experiment Tracking** | MLflow, Weights & Biases |
| **Orchestration** | Prefect |
| **Versioning** | DVC, HuggingFace Hub |
| **Evaluation** | Ragas, DeepEval |
| **Metrics** | Prometheus (5 alert rules) |
| **Dashboards** | Grafana (8-panel dashboard) |
| **Tracing** | LangFuse (LLM observability) |
| **Drift Detection** | Evidently |

### DevOps & Infrastructure
| Category | Technologies |
|----------|-------------|
| **CI/CD** | GitHub Actions (5-job pipeline) |
| **Containers** | Docker, Docker Compose |
| **IaC** | Terraform (18 files, 3 modules) |
| **Testing** | pytest, ruff, mypy |
| **Package Build** | Python build, setuptools |

## Internship Alignment

This project directly addresses LINAGORA internship requirements:

| Requirement | Implementation |
|-------------|----------------|
| VinaSmol evaluation | Ragas metrics + custom Vietnamese benchmarks |
| Vietnamese dataset creation | Common Crawl pipeline with language detection |
| RAG hallucination detection | Faithfulness scoring + factual consistency |
| GraphRAG exploration | Knowledge graph extraction (roadmap) |
| Agentic systems | LangGraph workflows (roadmap) |

## License

MIT License - See [LICENSE](LICENSE) for details.
